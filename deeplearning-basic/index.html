<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>신경망 학습</title>
  <meta name='description' content='These story for everything such as Life, develop and daily.'>

  <link rel="canonical" href="http://192.168.219.102:4000/deeplearning-basic/">
  <link rel="alternate" type="application/rss+xml" title="Mike Chu&#39;s Story | Thank you for visiting." href="/feed.xml">

  <!-- Google Font -->
  <link href="https://fonts.googleapis.com/css?family=Nunito:400,700" rel="stylesheet">
  <!-- Ionicons -->
  <link href="https://unpkg.com/ionicons@4.2.2/dist/css/ionicons.min.css" rel="stylesheet">

  <script data-ad-client="ca-pub-3911267540743441" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-138988094-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-138988094-1');
  </script>

  <style>
  
  /*! normalize.css v8.0.0 | MIT License | github.com/necolas/normalize.css */@import url(http://fonts.googleapis.com/earlyaccess/notosanskr.css);html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:sans-serif, sans-serif;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder;color:#24d5cc}code,kbd,samp{font-family:sans-serif, sans-serif;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,dl,dd,ol,ul,fieldset,legend,figure,hr{margin:0;padding:0}li>ul,li>ol{margin-bottom:0}table{border-collapse:collapse;border-spacing:0}h1,h2,h3,h4,h5,h6,ul,ol,dl,blockquote,p,address,hr,table,fieldset,figure,pre{margin-bottom:15px}ul,ol,dd{margin-left:15px}.highlight{background:#2C2F36}.highlight .c{color:#998;font-style:italic}.highlight .err{color:#a61717;background-color:#e3d2d2}.highlight .k{color:#c14bde;font-weight:bold}.highlight .o{font-weight:bold}.highlight .cm{color:#998;font-style:italic}.highlight .cp{color:#999;font-weight:bold}.highlight .c1{color:#998;font-style:italic}.highlight .cs{color:#999;font-weight:bold;font-style:italic}.highlight .gd{color:#000;background-color:#fdd}.highlight .gd .x{color:#000;background-color:#faa}.highlight .ge{font-style:italic}.highlight .gr{color:#a00}.highlight .gh{color:#999}.highlight .gi{color:#000;background-color:#dfd}.highlight .gi .x{color:#000;background-color:#afa}.highlight .go{color:#888}.highlight .gp{color:#555}.highlight .gs{font-weight:bold}.highlight .gu{color:#aaa}.highlight .gt{color:#a00}.highlight .kc{font-weight:bold}.highlight .kd{font-weight:bold;color:#ff8d00}.highlight .kp{font-weight:bold}.highlight .kr{font-weight:bold}.highlight .kt{color:#4e7cc1;font-weight:bold}.highlight .m{color:#099}.highlight .s{color:#099}.highlight .na{color:#00adad}.highlight .nb{color:#0086B3}.highlight .nc{color:#4e7cc1;font-weight:bold}.highlight .no{color:#00adad}.highlight .ni{color:purple}.highlight .ne{color:#6d1;font-weight:bold}.highlight .nf{color:#6d1;font-weight:bold}.highlight .nn{color:#555}.highlight .nt{color:#0086b3}.highlight .nv{color:#00adad}.highlight .ow{font-weight:bold}.highlight .w{color:#bbb}.highlight .mf{color:#099}.highlight .mh{color:#099}.highlight .mi{color:#099}.highlight .mo{color:#099}.highlight .sb{color:#6d1}.highlight .sc{color:#6d1}.highlight .sd{color:#6d1}.highlight .s2{color:#6d1}.highlight .se{color:#6d1}.highlight .sh{color:#6d1}.highlight .si{color:#6d1}.highlight .sx{color:#6d1}.highlight .sr{color:#009926}.highlight .s1{color:#6d1}.highlight .ss{color:#990073}.highlight .bp{color:#999}.highlight .vc{color:#00adad}.highlight .vg{color:#00adad}.highlight .vi{color:#00adad}.highlight .il{color:#099}.container{max-width:1200px;padding-left:15px;padding-right:15px;margin:0 auto}.container-full{max-width:100%;padding-left:15px;padding-right:15px;margin:0 auto}.row{display:flex;flex-wrap:wrap;flex:0 1 auto;flex-direction:row;box-sizing:border-box;margin-left:-15px;margin-right:-15px}.col{padding-left:15px;padding-right:15px}[class^="col-"]{flex:auto}.col-0{width:0%}.col-1{width:8.3333333333%}.col-2{width:16.6666666667%}.col-3{width:25%}.col-4{width:33.3333333333%}.col-5{width:41.6666666667%}.col-6{width:50%}.col-7{width:58.3333333333%}.col-8{width:66.6666666667%}.col-9{width:75%}.col-10{width:83.3333333333%}.col-11{width:91.6666666667%}.col-12{width:100%}.push-0{margin-left:0%}.push-1{margin-left:8.3333333333%}.push-2{margin-left:16.6666666667%}.push-3{margin-left:25%}.push-4{margin-left:33.3333333333%}.push-5{margin-left:41.6666666667%}.push-6{margin-left:50%}.push-7{margin-left:58.3333333333%}.push-8{margin-left:66.6666666667%}.push-9{margin-left:75%}.push-10{margin-left:83.3333333333%}.push-11{margin-left:91.6666666667%}.push-12{margin-left:100%}.pull-0{margin-right:0%}.pull-1{margin-right:8.3333333333%}.pull-2{margin-right:16.6666666667%}.pull-3{margin-right:25%}.pull-4{margin-right:33.3333333333%}.pull-5{margin-right:41.6666666667%}.pull-6{margin-right:50%}.pull-7{margin-right:58.3333333333%}.pull-8{margin-right:66.6666666667%}.pull-9{margin-right:75%}.pull-10{margin-right:83.3333333333%}.pull-11{margin-right:91.6666666667%}.pull-12{margin-right:100%}@media (min-width: 768px){.col-t-0{width:0%}.col-t-1{width:8.3333333333%}.col-t-2{width:16.6666666667%}.col-t-3{width:25%}.col-t-4{width:33.3333333333%}.col-t-5{width:41.6666666667%}.col-t-6{width:50%}.col-t-7{width:58.3333333333%}.col-t-8{width:66.6666666667%}.col-t-9{width:75%}.col-t-10{width:83.3333333333%}.col-t-11{width:91.6666666667%}.col-t-12{width:100%}.push-t-0{margin-left:0%}.push-t-1{margin-left:8.3333333333%}.push-t-2{margin-left:16.6666666667%}.push-t-3{margin-left:25%}.push-t-4{margin-left:33.3333333333%}.push-t-5{margin-left:41.6666666667%}.push-t-6{margin-left:50%}.push-t-7{margin-left:58.3333333333%}.push-t-8{margin-left:66.6666666667%}.push-t-9{margin-left:75%}.push-t-10{margin-left:83.3333333333%}.push-t-11{margin-left:91.6666666667%}.push-t-12{margin-left:100%}.pull-t-0{margin-right:0%}.pull-t-1{margin-right:8.3333333333%}.pull-t-2{margin-right:16.6666666667%}.pull-t-3{margin-right:25%}.pull-t-4{margin-right:33.3333333333%}.pull-t-5{margin-right:41.6666666667%}.pull-t-6{margin-right:50%}.pull-t-7{margin-right:58.3333333333%}.pull-t-8{margin-right:66.6666666667%}.pull-t-9{margin-right:75%}.pull-t-10{margin-right:83.3333333333%}.pull-t-11{margin-right:91.6666666667%}.pull-t-12{margin-right:100%}}@media (min-width: 992px){.col-d-0{width:0%}.col-d-1{width:8.3333333333%}.col-d-2{width:16.6666666667%}.col-d-3{width:25%}.col-d-4{width:33.3333333333%}.col-d-5{width:41.6666666667%}.col-d-6{width:50%}.col-d-7{width:58.3333333333%}.col-d-8{width:66.6666666667%}.col-d-9{width:75%}.col-d-10{width:83.3333333333%}.col-d-11{width:91.6666666667%}.col-d-12{width:100%}.push-d-0{margin-left:0%}.push-d-1{margin-left:8.3333333333%}.push-d-2{margin-left:16.6666666667%}.push-d-3{margin-left:25%}.push-d-4{margin-left:33.3333333333%}.push-d-5{margin-left:41.6666666667%}.push-d-6{margin-left:50%}.push-d-7{margin-left:58.3333333333%}.push-d-8{margin-left:66.6666666667%}.push-d-9{margin-left:75%}.push-d-10{margin-left:83.3333333333%}.push-d-11{margin-left:91.6666666667%}.push-d-12{margin-left:100%}.pull-d-0{margin-right:0%}.pull-d-1{margin-right:8.3333333333%}.pull-d-2{margin-right:16.6666666667%}.pull-d-3{margin-right:25%}.pull-d-4{margin-right:33.3333333333%}.pull-d-5{margin-right:41.6666666667%}.pull-d-6{margin-right:50%}.pull-d-7{margin-right:58.3333333333%}.pull-d-8{margin-right:66.6666666667%}.pull-d-9{margin-right:75%}.pull-d-10{margin-right:83.3333333333%}.pull-d-11{margin-right:91.6666666667%}.pull-d-12{margin-right:100%}}@media (min-width: 768px){.col-t-0{width:0%}.col-t-1{width:8.3333333333%}.col-t-2{width:16.6666666667%}.col-t-3{width:25%}.col-t-4{width:33.3333333333%}.col-t-5{width:41.6666666667%}.col-t-6{width:50%}.col-t-7{width:58.3333333333%}.col-t-8{width:66.6666666667%}.col-t-9{width:75%}.col-t-10{width:83.3333333333%}.col-t-11{width:91.6666666667%}.col-t-12{width:100%}.push-t-0{margin-left:0%}.push-t-1{margin-left:8.3333333333%}.push-t-2{margin-left:16.6666666667%}.push-t-3{margin-left:25%}.push-t-4{margin-left:33.3333333333%}.push-t-5{margin-left:41.6666666667%}.push-t-6{margin-left:50%}.push-t-7{margin-left:58.3333333333%}.push-t-8{margin-left:66.6666666667%}.push-t-9{margin-left:75%}.push-t-10{margin-left:83.3333333333%}.push-t-11{margin-left:91.6666666667%}.push-t-12{margin-left:100%}.pull-t-0{margin-right:0%}.pull-t-1{margin-right:8.3333333333%}.pull-t-2{margin-right:16.6666666667%}.pull-t-3{margin-right:25%}.pull-t-4{margin-right:33.3333333333%}.pull-t-5{margin-right:41.6666666667%}.pull-t-6{margin-right:50%}.pull-t-7{margin-right:58.3333333333%}.pull-t-8{margin-right:66.6666666667%}.pull-t-9{margin-right:75%}.pull-t-10{margin-right:83.3333333333%}.pull-t-11{margin-right:91.6666666667%}.pull-t-12{margin-right:100%}}@media (min-width: 992px){.col-d-0{width:0%}.col-d-1{width:8.3333333333%}.col-d-2{width:16.6666666667%}.col-d-3{width:25%}.col-d-4{width:33.3333333333%}.col-d-5{width:41.6666666667%}.col-d-6{width:50%}.col-d-7{width:58.3333333333%}.col-d-8{width:66.6666666667%}.col-d-9{width:75%}.col-d-10{width:83.3333333333%}.col-d-11{width:91.6666666667%}.col-d-12{width:100%}.push-d-0{margin-left:0%}.push-d-1{margin-left:8.3333333333%}.push-d-2{margin-left:16.6666666667%}.push-d-3{margin-left:25%}.push-d-4{margin-left:33.3333333333%}.push-d-5{margin-left:41.6666666667%}.push-d-6{margin-left:50%}.push-d-7{margin-left:58.3333333333%}.push-d-8{margin-left:66.6666666667%}.push-d-9{margin-left:75%}.push-d-10{margin-left:83.3333333333%}.push-d-11{margin-left:91.6666666667%}.push-d-12{margin-left:100%}.pull-d-0{margin-right:0%}.pull-d-1{margin-right:8.3333333333%}.pull-d-2{margin-right:16.6666666667%}.pull-d-3{margin-right:25%}.pull-d-4{margin-right:33.3333333333%}.pull-d-5{margin-right:41.6666666667%}.pull-d-6{margin-right:50%}.pull-d-7{margin-right:58.3333333333%}.pull-d-8{margin-right:66.6666666667%}.pull-d-9{margin-right:75%}.pull-d-10{margin-right:83.3333333333%}.pull-d-11{margin-right:91.6666666667%}.pull-d-12{margin-right:100%}}@media (min-width: 768px){.col-t-0{width:0%}.col-t-1{width:8.3333333333%}.col-t-2{width:16.6666666667%}.col-t-3{width:25%}.col-t-4{width:33.3333333333%}.col-t-5{width:41.6666666667%}.col-t-6{width:50%}.col-t-7{width:58.3333333333%}.col-t-8{width:66.6666666667%}.col-t-9{width:75%}.col-t-10{width:83.3333333333%}.col-t-11{width:91.6666666667%}.col-t-12{width:100%}.push-t-0{margin-left:0%}.push-t-1{margin-left:8.3333333333%}.push-t-2{margin-left:16.6666666667%}.push-t-3{margin-left:25%}.push-t-4{margin-left:33.3333333333%}.push-t-5{margin-left:41.6666666667%}.push-t-6{margin-left:50%}.push-t-7{margin-left:58.3333333333%}.push-t-8{margin-left:66.6666666667%}.push-t-9{margin-left:75%}.push-t-10{margin-left:83.3333333333%}.push-t-11{margin-left:91.6666666667%}.push-t-12{margin-left:100%}.pull-t-0{margin-right:0%}.pull-t-1{margin-right:8.3333333333%}.pull-t-2{margin-right:16.6666666667%}.pull-t-3{margin-right:25%}.pull-t-4{margin-right:33.3333333333%}.pull-t-5{margin-right:41.6666666667%}.pull-t-6{margin-right:50%}.pull-t-7{margin-right:58.3333333333%}.pull-t-8{margin-right:66.6666666667%}.pull-t-9{margin-right:75%}.pull-t-10{margin-right:83.3333333333%}.pull-t-11{margin-right:91.6666666667%}.pull-t-12{margin-right:100%}}@media (min-width: 992px){.col-d-0{width:0%}.col-d-1{width:8.3333333333%}.col-d-2{width:16.6666666667%}.col-d-3{width:25%}.col-d-4{width:33.3333333333%}.col-d-5{width:41.6666666667%}.col-d-6{width:50%}.col-d-7{width:58.3333333333%}.col-d-8{width:66.6666666667%}.col-d-9{width:75%}.col-d-10{width:83.3333333333%}.col-d-11{width:91.6666666667%}.col-d-12{width:100%}.push-d-0{margin-left:0%}.push-d-1{margin-left:8.3333333333%}.push-d-2{margin-left:16.6666666667%}.push-d-3{margin-left:25%}.push-d-4{margin-left:33.3333333333%}.push-d-5{margin-left:41.6666666667%}.push-d-6{margin-left:50%}.push-d-7{margin-left:58.3333333333%}.push-d-8{margin-left:66.6666666667%}.push-d-9{margin-left:75%}.push-d-10{margin-left:83.3333333333%}.push-d-11{margin-left:91.6666666667%}.push-d-12{margin-left:100%}.pull-d-0{margin-right:0%}.pull-d-1{margin-right:8.3333333333%}.pull-d-2{margin-right:16.6666666667%}.pull-d-3{margin-right:25%}.pull-d-4{margin-right:33.3333333333%}.pull-d-5{margin-right:41.6666666667%}.pull-d-6{margin-right:50%}.pull-d-7{margin-right:58.3333333333%}.pull-d-8{margin-right:66.6666666667%}.pull-d-9{margin-right:75%}.pull-d-10{margin-right:83.3333333333%}.pull-d-11{margin-right:91.6666666667%}.pull-d-12{margin-right:100%}}@media (min-width: 992px){.d-hide{display:none !important}.d-show{display:block !important}}*,*::after,*::before{box-sizing:border-box}body{font-family:‘Noto Sans’;font-size:16px;line-height:28px;color:#fbeeee;background:#2C2F36;overflow-x:hidden;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}body input,body textarea{border:#3E4250 1px solid;outline:none}body input:focus:required:invalid,body textarea:focus:required:invalid{border-color:#e02f40}body input:required:valid,body textarea:required:valid{border-color:#34a74e}::placeholder{color:#666}*::selection{color:#fff;background-color:#1ABC9C}h1,h2,h3,h4,h5,h6{line-height:initial}h1{font-size:36px}h2{font-size:28px}h3{font-size:24px}h4{font-size:20px}h5{font-size:18px}h6{font-size:16px}blockquote{padding-left:15px;border-left:3px solid #1ABC9C;font-style:normal;color:#a2a9b8}pre{overflow:auto;padding:15px;margin-bottom:0;font-size:12px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all}img{max-width:100%;height:auto;vertical-align:middle}img+em{text-align:center;display:block;margin-top:10px;font-weight:normal;font-size:16px;color:#a8adba}a{text-decoration:none;color:#1ABC9C;transition:.35s}a:hover{color:#3ee4c4}hr{display:block;height:2px;padding:0;margin:30px 0;line-height:0;border:0;background-color:#3E4250}blockquote{padding:10px 10px 10px 20px;font-size:14px;font-style:normal;border-left:4px solid #1ABC9C}blockquote p{margin-bottom:0}pre{overflow:auto;padding:15px;margin-bottom:0;font-size:14px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all}.table-container{max-width:100%;overflow-x:auto}table{font-size:12px;color:#101010;width:100%;border-width:1px;border-color:#a8adba;border-collapse:collapse}table th{padding:8px;font-size:16px;text-align:left;border:1px solid #a8adba;color:#fff;background-color:#454545}table tr{background-color:#c8d1cf;transition:all .3s ease}table tr:nth-child(even){background-color:#fff}table td{padding:8px;font-size:14px;border:1px solid #a8adba}table tr:hover{background-color:#fff}.preloader{position:fixed;top:0;left:0;right:0;bottom:0;z-index:999;overflow:hidden;background:#101010}.loader{position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);padding:10px;font-family:'Nunito', sans-serif;font-size:21px;letter-spacing:.5em;text-transform:uppercase;font-weight:700;color:#fff;background:#101010}.loader span{color:#fff;mix-blend-mode:difference}.loader:before{content:'';position:absolute;top:0;left:0;width:60px;height:100%;background:#fff;animation:animate 3s linear infinite}@keyframes animate{0%{left:0}50%{left:calc(100% - 70px)}100%{left:0}}.button{display:inline-block;white-space:nowrap;vertical-align:middle;font:inherit;text-align:center;padding:8px 30px;border-radius:3px;cursor:pointer;transition:.35s}.button--primary{color:#fff;background-color:#1ABC9C}.button--primary:hover{background-color:#117964;color:#fff;transition:.35s}.button--big{display:block;width:100%}.sidebar{margin-bottom:30px}.widget{padding:40px 15px;margin-bottom:30px;background:rgba(35,36,39,0.95);box-shadow:0 9px 18px 0 rgba(0,0,0,0.25)}.widget .widget-title{position:relative;padding-bottom:15px;margin-bottom:20px;font-size:21px;text-align:center}.widget .widget-title:after{content:"";position:absolute;left:50%;bottom:0;transform:translateX(-50%);display:block;width:50px;height:2px;background:#3E4250}.recent-posts{display:flex;flex-wrap:wrap;align-items:center;margin-bottom:15px}.recent-posts:hover .recent-image::before{background:rgba(0,0,0,0.15);transition:all .5s ease}.recent-posts:hover .recent-content .recent-title a{color:#3ee4c4}.recent-posts:last-child{margin-bottom:0}.recent-posts .recent-header{width:100%;margin-bottom:10px;background:#101010}.recent-posts .recent-header.reveal-in .recent-image{opacity:1}.recent-posts .recent-image{position:relative;display:block;width:100%;height:220px;background-size:cover;background-position:center;background-repeat:no-repeat;background-color:#101010;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25);opacity:0;transition:all 1s cubic-bezier(0.6, 0.3, 0, 1)}.recent-posts .recent-image:after{content:"";display:table;padding-top:20%}.recent-posts .recent-image:before{content:"";position:absolute;width:100%;height:100%;transition:all .5s ease}.recent-posts .recent-content{margin:5px 0}.recent-posts .recent-content .recent-title{margin-bottom:0;font-weight:700}.recent-posts .recent-content .recent-title a{font-size:18px;color:#fbeeee}.recent-posts .recent-content .recent-date{font-size:12px;color:#a8adba}.social-profiles{text-align:center}.social-profiles .social-profiles-item{display:inline-block;margin:3px}.social-profiles .social-profiles-link{display:inline-block;line-height:16px;padding:8px 10px;border:1px solid #3E4250;border-radius:3px;color:#3E4250}.social-profiles .social-profiles-link:hover{border-color:#1ABC9C;color:#1ABC9C}.social-profiles .social-profiles-link i{font-size:18px}.widget-instagram .instagram-box{text-align:center}.widget-instagram .instagram-box .instagram-grid{margin-bottom:30px}.widget-instagram .instagram-box .instagram-item{width:33.333%;padding:3px;float:left;overflow:hidden}.widget-instagram .instagram-box .instagram-item a{position:relative;display:block}.widget-instagram .instagram-box .instagram-item a:after{content:"";position:absolute;top:0;display:block;height:100%;width:100%;background:rgba(35,36,39,0.3);transition:.35s}.widget-instagram .instagram-box .instagram-item a:hover:after{background:transparent}.widget-instagram .instagram-box .instagram-prof{font-size:14px;color:#3E4250}.widget-instagram .instagram-box .instagram-prof:hover{text-decoration:underline}.widget-newsletter{text-align:center}.widget-newsletter .newsletter-subtitle{margin-bottom:20px;font-size:18px}.widget-newsletter .newsletter-text{max-width:170px;margin:0 auto 30px;font-size:14px;line-height:19px}.widget-newsletter .newsletter-group-top{position:relative}.widget-newsletter .email-icon{position:absolute;top:50%;left:10px;font-size:22px;transform:translateY(-50%);color:rgba(44,47,54,0.4)}.widget-newsletter .newsletter-email,.widget-newsletter .newsletter-button{width:100%;height:50px;border:none;outline:none}.widget-newsletter .newsletter-email{padding:15px 15px 15px 33px}.widget-newsletter .newsletter-button{margin-top:20px;font-size:14px;font-weight:700;cursor:pointer;color:#fff;background:#2C2F36;transition:.35s}.widget-newsletter .newsletter-button:hover{background:#1ABC9C}.tag-list .tag-item{display:inline-block;margin:3px}.tag-list .tag-item:last-child{margin-right:0}.tag-list .tag-item .tag{display:inline-block;padding:5px 15px;font-size:12px;border-radius:3px;color:#fbeeee;background:#2C2F36}.tag-list .tag-item .tag:hover{color:#fff;background:#1ABC9C}@media only screen and (min-width: 576px){.widget{padding:40px}}@media only screen and (min-width: 768px){.recent-posts .recent-header{margin-bottom:5px}.recent-posts .recent-image{height:120px}.recent-posts .recent-content .recent-title a{font-size:16px}}@media only screen and (min-width: 992px){.recent-posts{flex-wrap:nowrap}.recent-posts .recent-header{width:auto;margin-right:15px}.recent-posts .recent-image{width:110px}}.pagination{margin:20px 0 40px}.pagination .pagination-list{display:flex;align-items:center;text-align:center}.pagination .pagination-list .older-posts,.pagination .pagination-list .previous-posts,.pagination .pagination-list .newer-posts{display:inline-block;flex-grow:1}.pagination .pagination-list .older-posts .older-link,.pagination .pagination-list .older-posts .previous-link,.pagination .pagination-list .older-posts .newer-link,.pagination .pagination-list .previous-posts .older-link,.pagination .pagination-list .previous-posts .previous-link,.pagination .pagination-list .previous-posts .newer-link,.pagination .pagination-list .newer-posts .older-link,.pagination .pagination-list .newer-posts .previous-link,.pagination .pagination-list .newer-posts .newer-link{display:flex;justify-content:center;align-items:center;padding:20px 35px;font-size:14px;line-height:18px;font-weight:bold;color:#fbeeee;background:rgba(35,36,39,0.95);transition:.35s}.pagination .pagination-list .older-posts .older-link:hover,.pagination .pagination-list .older-posts .previous-link:hover,.pagination .pagination-list .older-posts .newer-link:hover,.pagination .pagination-list .previous-posts .older-link:hover,.pagination .pagination-list .previous-posts .previous-link:hover,.pagination .pagination-list .previous-posts .newer-link:hover,.pagination .pagination-list .newer-posts .older-link:hover,.pagination .pagination-list .newer-posts .previous-link:hover,.pagination .pagination-list .newer-posts .newer-link:hover{background:rgba(28,29,31,0.95)}.pagination .pagination-list .older-link i{margin-left:10px}.pagination .pagination-list .previous-link i,.pagination .pagination-list .newer-link i{margin-right:10px}@media only screen and (min-width: 768px){.pagination{margin:20px 0}}.footer{padding:50px 0;margin-top:30px;background:#101010}.footer-top{display:flex;justify-content:space-between;align-items:center;padding-bottom:15px;margin-bottom:10px;border-bottom:1px solid #3E4250}.footer-top .logo-text{font-size:16px;font-weight:700;line-height:16px;text-transform:uppercase;letter-spacing:5px;color:#fbeeee}.footer-top .logo-text:hover{color:#a8adba}.footer-top .top{display:flex;justify-content:center;align-items:center;width:30px;height:30px;border:1px solid #2C2F36;background-color:#2C2F36;color:#fbeeee;cursor:pointer;transition:.35s;opacity:.5}.footer-top .top:hover{opacity:1}.footer-bottom{display:flex;align-items:center;flex-wrap:wrap}.footer-bottom .copyright{margin-right:60px}.footer-bottom .copyright p{margin-bottom:0;font-size:13px;color:#a8adba}.footer-bottom .copyright p a{color:#a8adba}.footer-bottom .copyright p a:hover{color:#1ABC9C}.footer-bottom .footer-social ul li{display:inline-block;margin-left:15px}.footer-bottom .footer-social ul li:first-child{margin-left:0}.footer-bottom .footer-social ul li a{font-size:13px;font-weight:bold;color:#a8adba;transition:.35s}.footer-bottom .footer-social ul li a:hover{color:#1ABC9C}.header{margin-bottom:50px;background:#101010}.header,.header-box{height:60px}.header-box{display:flex;flex-direction:row;justify-content:space-between;align-items:center}.header-box .logo-title .logo-text{font-size:16px;font-weight:700;line-height:16px;text-transform:uppercase;letter-spacing:5px;color:#fbeeee}.header-box .logo-title .logo-text:hover{color:#fff}.nav-menu,.search{position:fixed;top:0;left:0;right:0;bottom:0;transform:scale(0.5);z-index:-1;background:#2C2F36;overflow-y:auto;opacity:0}.nav-menu.active,.search.active{transition:all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);transform:scale(1);z-index:10;opacity:1}.menu-list{max-width:750px;width:100%;margin:5% auto 0;padding:15px;list-style:none;overflow-y:auto}.menu-list .menu-item{text-align:center}.menu-list .menu-link{position:relative;font-size:30px;font-weight:700;line-height:60px;color:#fbeeee}.menu-list .menu-link:before{content:'';position:absolute;left:0;bottom:0;width:100%;height:5px;pointer-events:none;background:#3DDCA1;transform:scale3d(0, 1, 1);transform-origin:100% 50%;transition:transform 0.35s cubic-bezier(0.8, 0, 0.2, 1)}.menu-list .menu-link:hover:before{transform:scale3d(1, 1, 1);transform-origin:0 50%}.search-close-button{margin:0 auto 50px}.menu-close{margin:20% auto 0}.menu-close,.search-close-button{display:flex;justify-content:center;align-items:center;width:40px;height:40px;font-size:40px;border-radius:50%;border:2px solid #a8adba;color:#a8adba;transition:all .35s;cursor:pointer}.menu-close:hover,.search-close-button:hover{border-color:#fbeeee;color:#fbeeee}.nav-menu .menu-link,.nav-buttons i.ion{transition:color .35s}.nav-menu .menu-link:hover,.nav-buttons i.ion:hover{color:#fff}.nav-buttons i.ion{margin-left:10px;font-size:20px;vertical-align:middle;color:#fbeeee;cursor:pointer}.nav-buttons i.ion:first-child{margin-left:0}.search-box{max-width:750px;width:100%;margin:10% auto 0;padding:15px;text-align:center}.search-box .search-text{width:100%;height:60px;margin-bottom:30px;text-align:center;font-size:18px;font-weight:700;letter-spacing:2px;text-transform:uppercase;color:#c1c1c7;background:#4f505d}.search-box .search-text::placeholder{color:#c1c1c7}.search-results-list{margin:0}.search-results-list .search-item{margin-bottom:15px;list-style:decimal inside;text-align:left;border-bottom:2px solid #323743;white-space:nowrap}.search-results-list .search-item .search-link{display:inline-block;width:100%;padding:15px;font-size:21px;color:#fff;white-space:normal}.search-results-list .search-item .search-link:hover{color:#a8adba}.search-results-list .search-no-item{font-size:18px;color:#e02f40;list-style:none}.article-first{margin-bottom:30px;background:#101010}.article-first .article-image-first{position:relative;display:flex;align-items:center;min-height:450px;background-size:cover;background-position:center;background-repeat:no-repeat;background-color:#101010;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25)}.article-first .article-image-first:before{content:"";display:table;padding-top:50%}.article-first .article-content-first{padding:3% 30% 3% 3%;color:#fbeeee;background-color:#565656e6}.article-first .article-content-first .article-tag .tag{font-size:12px}.article-first .article-content-first .article-date .date{font-size:12px;color:rgba(251,238,238,0.8)}.article-first .article-content-first .article-title{font-size:30px;line-height:30px;font-weight:normal;margin-bottom:15px}.article-first .article-content-first .article-title a{color:#fbeeee;transition:.35s}.article-first .article-content-first .article-excerpt{max-width:450px;margin-bottom:30px;font-size:14px;line-height:23px}.article-first .article-content-first .button{font-size:14px;font-weight:700;border:1px solid #c9d3e7;color:#fbeeee;transition:.35s}.article-first .article-content-first .button:hover{border:1px solid #1ABC9C;background:#1ABC9C;color:#fff}.article{display:flex;margin-bottom:25px}.article:hover .article-image .image-overlay-text{opacity:1}.article:hover .article-image .image-overlay{opacity:.5;width:100%}.article .article-box{padding-bottom:20px;border-bottom:2px solid #3E4250}.article .article-head{background:#101010}.article .article-image{position:relative;display:block;margin-bottom:20px;background-size:cover;background-position:center;background-repeat:no-repeat;background-color:#101010;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25)}.article .article-image:before{content:"";display:table;padding-top:75%}.article .article-image .image-overlay{position:absolute;top:0;right:0;bottom:0;left:0;width:0;height:100%;background-color:rgba(0,0,0,0.8);opacity:0;transition:all 0.4s ease}.article .article-image .image-overlay-text{position:absolute;top:50%;left:50%;font-size:110px;text-align:center;letter-spacing:2px;color:#fbeeee;transform:translate(-50%, -50%);transition:all 0.4s ease 0.3s;opacity:0}.article .article-content .article-info{display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;margin-bottom:5px}.article .article-content .article-info .article-date{font-size:12px;color:rgba(251,238,238,0.8)}.article .article-content .article-info .article-tag .tag{display:inline-block;padding:2px 5px;margin-right:5px;font-size:12px;line-height:18px;font-weight:bold;border:1px solid #1ABC9C;border-radius:3px;text-transform:capitalize;color:#1ABC9C;transition:.35s}.article .article-content .article-info .article-tag .tag:last-child{margin-right:0}.article .article-content .article-info .article-tag .tag:hover{background:#1ABC9C;color:#fff}.article .article-content .article-title{margin-bottom:5px}.article .article-content .article-title a{font-size:24px;color:#fbeeee}.article .article-content .article-excerpt{margin-bottom:0;font-size:15px;line-height:25px;color:#a8adba}.article-box{position:relative;overflow:hidden}.article-first .article-image-first,.article-box .article-image{position:relative;opacity:0;transition:all 1s cubic-bezier(0.6, 0.3, 0, 1)}.article-first.reveal-in .article-image-first,.article-box.reveal-in .article-image{opacity:1}@media only screen and (min-width: 576px){.article-first .article-content-first .article-title{font-size:45px;line-height:45px}.article-first .article-content-first .article-excerpt{margin-bottom:50px}.menu-list .menu-link{font-size:50px;line-height:80px}.menu-list .menu-link:before{height:8px}.search-box .search-text{height:80px;margin-bottom:30px;font-size:24px}}@media only screen and (min-width: 768px){.article-first .article-content-first{padding:3% 30% 3% 3%}}@media only screen and (min-width: 992px){.nav-menu{position:relative;display:block;transform:none;opacity:1;z-index:10;background:transparent}.nav-menu .menu-list{padding:0;margin:0}.nav-menu .menu-list .menu-item{display:inline-block;margin:0 15px 0 0}.nav-menu .menu-list .menu-item:last-child{margin-right:0}.nav-menu .menu-list .menu-link{font-size:13px;font-weight:700;text-transform:uppercase;line-height:19px}.nav-menu .menu-list .menu-link:before{content:none}.nav-menu .menu-close{display:none}.nav-menu .menu-link,.nav-buttons i.ion{transition:color .35s}.nav-menu .menu-link:hover,.nav-buttons i.ion:hover{color:#fff}}.post{margin-bottom:20px}.post-image-box{background:#101010}.post-image-box.reveal-in .post-image{opacity:1}.post-image{min-height:430px;margin-bottom:30px;background-size:cover;background-position:center;background-repeat:no-repeat;background-color:#101010;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25);position:relative;opacity:0;transition:all 1s cubic-bezier(0.6, 0.3, 0, 1)}.post-image:after{content:"";display:table;width:100%;padding-top:50%}.post-head,.post-content{background:rgba(35,36,39,0.95)}.post-content{padding:40px 15px;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25)}.post-head,.post-body{margin-bottom:20px;border-bottom:1px solid #3E4250}.post-head{padding-bottom:30px}.post-head .post-tag{margin-bottom:20px;text-align:center}.post-head .post-tag .tag{display:inline-block;padding:5px 15px;margin-right:5px;font-size:12px;line-height:18px;font-weight:bold;border:1px solid #1ABC9C;text-transform:capitalize;color:#1ABC9C;transition:.35s}.post-head .post-tag .tag:last-child{margin-right:0}.post-head .post-tag .tag:hover{background:#1ABC9C;color:#fff}.post-head .post-title{font-size:28px;text-align:center;font-weight:normal;line-height:28px;margin-bottom:5px}.post-head .post-date span{font-size:12px}.post-info,.post-info-author{display:flex;justify-content:center;align-items:center;flex-wrap:wrap}.post-info .post-info-author .info-author-avatar{display:inline-block;width:32px;height:32px;margin-right:10px;border-radius:50%;background-position:center;background-size:cover;background-repeat:no-repeat}.post-info .post-info-author .info-author-name,.post-info .post-info-author span{font-size:12px;text-transform:uppercase}.post-info .post-info-author span{margin-right:10px}.post-info .post-info-author .info-author-name{position:relative;padding-right:20px;margin-right:15px;color:#fbeeee}.post-info .post-info-author .info-author-name:after{content:"";position:absolute;top:50%;right:0;transform:translateY(-50%);display:block;width:2px;height:12px;background:#3E4250}.post-body{padding-bottom:20px}.post-share{padding:10px 0}.post-share .share-item{display:inline-block;padding-right:15px}.post-share .share-item a{color:#3E4250}.post-share .share-item a:hover{color:#1ABC9C}.post-share .share-item a i.ion{font-size:20px}.post-navigation{display:flex;flex-wrap:wrap;margin-top:30px}.prev,.next{flex-basis:100%;padding:15px;background:#26272B}.prev:hover,.next:hover{background:#1f2023}.prev:hover .post-nav-title,.next:hover .post-nav-title{color:#1ABC9C;transition:.35s}.prev .post-nav-arrow,.next .post-nav-arrow{font-size:14px;color:#fbeeee}.prev .post-nav-title,.next .post-nav-title{font-size:18px;color:#fbeeee;transition:.35s}.prev{margin-bottom:10px}.prev,.next{text-align:center}.comments{padding:0 15px;background:#232427}@media only screen and (min-width: 576px){.post-content{padding:40px}.post-head .post-title{font-size:43px;line-height:43px;margin-bottom:10px}.post-navigation{display:flex;justify-content:space-between;flex-wrap:nowrap}.prev,.next{flex-basis:48%;padding:20px}.prev .post-nav-title,.next .post-nav-title{font-size:21px}.prev{text-align:left;margin-bottom:0}.next{text-align:right}.comments{padding:0 40px}}.page{margin-bottom:20px}.page-image-box{background:#101010}.page-image-box.reveal-in .page-image{opacity:1}.page-image{min-height:230px;margin-bottom:30px;background-size:cover;background-position:center;background-repeat:no-repeat;background-color:#101010;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25);opacity:0;transition:all 1s cubic-bezier(0.6, 0.3, 0, 1)}.page-image:after{content:"";display:table;width:100%;padding-top:50%}.page-content{padding:40px 15px;box-shadow:0 9px 18px 0 rgba(0,0,0,0.25);background:rgba(35,36,39,0.95)}.page-head{padding-bottom:30px}.page-head .page-title{font-size:28px;text-align:center;font-weight:normal;line-height:28px;margin-bottom:0}.page-head,.page-body{margin-bottom:20px;border-bottom:1px solid #3E4250}.page-body{padding-bottom:20px}@media only screen and (min-width: 576px){.page-content{padding:40px}.page-head .page-title{font-size:43px;line-height:43px;margin-bottom:10px}}.tags-list{display:flex;flex-wrap:wrap;margin:40px 0;padding:0;list-style:none}.tags-list .tags-item{margin:5px}.tags-list .tags-link{display:inline-block;padding:7px 12px;font-size:14px;border-radius:4px;color:#fbeeee;font-weight:700;background:#2C2F36}.tags-list .tags-link:hover{color:#fff;background:#1ABC9C}.tags-title{margin-bottom:5px}.tags-group{margin-bottom:30px}.text-left{text-align:left}.text-right{text-align:right}.text-center{text-align:center}.text-justify{text-align:justify}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.vertical-center{display:flex;align-items:center;justify-content:center}.show{display:block !important}.hide{display:none !important}.invisible{visibility:hidden}.float-left{float:left}.float-right{float:right}.no-padding{padding:0}.no-margin{margin:0}.clearfix::after,.clearfix ::before{content:"";display:table;clear:both}.list-reset{list-style-type:none;margin:0;padding:0}.screen-reader-text{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}

  </style>
</head>


<body>

  
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '{"ua"=>"UA-72007721-1"}', 'auto');
  ga('send', 'pageview');
</script>
  
  <div class="preloader">
  <div class="loader">
    <span>Loading</span>
  </div>
</div> <!-- /.loader -->
  <header class="header">
  <div class="container">
    <div class="row">
      <div class="col col-12">
        <div class="header-box">
          <div class="logo-title">
            <a href="/" class="logo-text">Mike Chu</a>
          </div>

          <nav class="nav-menu">
            <i class="menu-close ion ion-ios-close"></i>
            <ul class="menu-list">
              <li class="menu-item"><a href="/" class="menu-link">Home</a></li>
              <li class="menu-item"><a href="/tags" class="menu-link">tags</a></li>
              
                
              
                
              
              <li class="menu-item"><a href="/about/" class="menu-link">About</a></li>
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
            </ul>
          </nav>
          <div class="nav-buttons">
            <i class="menu-button d-hide ion ion-ios-menu"></i>
            <i class="search-button ion ion-ios-search"></i>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="search">
    <div class="search-box">
      <i class="search-close-button ion ion-ios-close"></i>
      <label for="js-search-input" class="screen-reader-text"></label>
      <input type="text" id="js-search-input" class="search-text" autocomplete="off" placeholder="Search Something...">
      <ol id="js-results-container" class="search-results-list"></ol>
    </div>
  </div>
</header> <!-- /.header -->


      <div class="container">
	<div class="row">
		<div class="col col-12">
			<div class="post-image-box">
				<div class="post-image" style="background-image: url(/img/01.jpg)"></div>
			</div>
		</div>
	</div>
</div>

<div class="container">
	<div class="row">
		<article class="col col-12 col-t-8 post">
			<div class="post-content">

				<div class="post-head">
					
					<div class="post-tag">
						
						<a href="/tags#Deep Learning" class="tag">Deep Learning</a>
						
						<a href="/tags#손실함수" class="tag">손실함수</a>
						
						<a href="/tags#신경망" class="tag">신경망</a>
						
					</div>
					
					<h1 class="post-title">신경망 학습</h1>
					<div class="post-info">
						<div class="post-info-author">
							<div class="info-author-avatar" style="background-image: url(/img/mike.chu.jpg)"></div>
							<span>by</span>
							<span class="info-author-name">Mike Chu</span>
						</div>
						<div class="post-date">
							<span>
								<time datetime="2021-07-20T23:21:42+09:00">Jul 20, 2021</time>
							</span>
						</div>
					</div>
				</div>

				<div class="post-body">
					<h2 id="overview">Overview</h2>
<p>인공지능 중 신경망 학습에 대해서 다루도록 하겠습니다. 특히, 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻하는 <strong>학습</strong>과 학습 결과를 판단할 수 있는 지표인 <strong>손실 함수</strong>에 대해서 작성하였습니다.<br />
<span style="color: grey"><em>이 글은 “밑바닥부터 시작하는 딥러닝”을 읽으면서 작성되었습니다.</em><br />
<em>예제 출처는 다음과 같습니다.<a href="https://github.com/WegraLee/deep-learning-from-scratch">github</a></em>  </span><br />
<br />
<a href="#데이터-주도-학습">1. 데이터 주도 학습</a><br />
<a href="#손실-함수">2. 손실 함수</a><br />
<a href="#수치-미분">3. 수치 미분</a><br />
<a href="#기울기">4. 기울기</a><br />
<a href="#학습-알고리즘-구현하기">5. 학습 알고리즘 구현하기</a><br />
<a href="#마치며">6. 마치며</a></p>

<h2 id="데이터-주도-학습">데이터 주도 학습</h2>
<p>기계학습 중 신경망은 데이터의 사람이 생각하고 파악한 특징을 분류하는 과정을 데이터 있는 그대로 활용하여 사람이 개입도 들어가지 않고, 방대한 데이터가 주어졌을 때, 분류(<em>혹은 설계</em>)하는 작업을 줄일 수 있습니다. 그렇게 되어 end-to-end machine learning(<em>종단간 기계학습</em>)이 가능하게 해주는 것 입니다.<br />
즉, 기계가 스스로 학습을 하게되고, 특징 또한 스스로 판단할 수 있습니다. 이렇게 되면 이점은 모든 문제를 같은 맥락에서 풀 수 있다는 점에 있습니다.</p>
<p align="center"><img src="../img/deep_1.png" /></p>
<p><br /></p>

<h3 id="훈련-데이터와-시험-데이터">훈련 데이터와 시험 데이터</h3>
<p>책에서는 본격적인 신경망 학습 설명에 앞서, 기계학습 데이터 취급에 대해서 설명하고 있습니다. 기계학습은 <strong>훈련 데이터</strong>와 <strong>시험 데이터</strong>로 나눠 학습과 실험을 수행하는 것이 일반적입니다. 우선, 훈련 데이터만 사용하여 학습하여 최적의 매개변수를 찾고, 시험 데이터를 이용하여 평가를 합니다.<br />
이렇게 하는 이유는 <strong>범용 능력</strong>을 제대로 평가하기 위함이라고 합니다. 범용 능력은 아직 보지 못한 데이터(훈련 데이터에 포함되지 않는 데이터)로도 문제를 올바르게 풀어내는 능력입니다. 만약 특정 데이터에 대해서 판단이 잘 된다면, 그 데이터로만 학습했을 가능성이 크며, 한 특성의 데이터에 지나치게 최적화된 상태(편견이 들어버린 상태)를 <strong>오버피팅</strong>이라고 합니다.</p>

<hr />

<h2 id="손실-함수">손실 함수</h2>
<p>우리는 어느 것의 성능을 판단할 때, 수치를 많이 씁니다. <strong>손실 함수</strong>는 신경망 성능의 ‘나쁨’을 나타내는 지표로 신경망이 훈련 데이터를 얼마나 잘 처리하지 못하느냐를 나타냅니다. 손실 함수는 임의의 함수를 사용하여 나타낼 수도 있지만 일반적으로 <strong>평균 제곱 오차</strong>와 교체 <strong>엔트로피 오차</strong>를 사용합니다.<br />
<br /></p>

<h3 id="평균-제곱-오차">평균 제곱 오차</h3>
<p align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\bg_black&space;E&space;=&space;\frac{1}{2}\sum_{k}^{}(y_k&space;-&space;t_k)^2" target="_blank"><img src="https://latex.codecogs.com/png.latex?\bg_black&space;E&space;=&space;\frac{1}{2}\sum_{k}^{}(y_k&space;-&space;t_k)^2" title="E = \frac{1}{2}\sum_{k}^{}(y_k - t_k)^2" /></a></p>
<p>가장 많이 쓰이는 평균제곱오차 입니다. 여기서 yk는 신경망의 출력(신경망이 추정한 값), tk는 정답 레이블, k는 데이터의 차원 수를 나타냅니다. MNIT 예시로 책에서는 설명하고 있으므로 책의 예제를 그대로 소개 하겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,]</span>
</code></pre></div></div>
<p><br /></p>

<p><a href="https://www.kaggle.com/c/digit-recognizer">MNIT</a>는 이런 데이터셋을 참고하면 됩니다. 여기서 y는 0~9의 각 값일 확률이고, t는 정답을 가리키는 원소로 여기서는 2의 위치의 값이 ‘1’이므로 정답이 ‘2’ 임을 알 수 있습니다. 평균 제곱을 결과로 확인하면 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
  <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># '2' 를 가장 높은 확률로 추정함
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,]</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">0.09750000000000003</span>

<span class="c1"># '7'을 가장 높은 확률로 추정함
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">0.5975</span>
</code></pre></div></div>
<p><br />
여기서 평균제곱오차 기준으로 첫 추정 결과가 오차가 적으므로 더 정답에 가까운 판단으로 알 수 있습니다.<br />
<br /></p>

<h3 id="교차-엔트로피-오차">교차 엔트로피 오차</h3>
<p align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\bg_black&space;E&space;=&space;-\sum_{k}^{}t_kln{y_k}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\bg_black&space;E&space;=&space;-\sum_{k}^{}t_kln{y_k}" title="E = -\sum_{k}^{}t_kln{y_k}" /></a></p>
<p>교차 엔트로피 오차도 자주 이용한다고 합니다. 수식을 보듯이 tk는 0 또는 1인(원-핫 인코딩) 값이므로 정답에 의해 오차율이 결정되는 간단한 식입니다. 특히 정답에 가까울 수록 0에 가까운 특징을 가지므로 확인도 편합니다. 코드로 표현하면 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
  <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-7</span>
  <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">delta</span><span class="p">))</span>

<span class="c1"># '2' 를 가장 높은 확률로 추정함
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,]</span>
<span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">0.510825457099338</span>

<span class="c1"># '7'을 가장 높은 확률로 추정함
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">2.302584092994546</span>
</code></pre></div></div>
<p><br /></p>

<p>delta 값을 넣어준 이유는 np.log 에서 0을 입력하면 마이너스 무한대를 뜻하므로 계산을 할 수 없게 됩니다. 결과를 분석하면 낮은 값을 가질 수록 정답에 가깝다고 판단할 수 있습니다.<br />
<br /></p>

<h3 id="미니배치">미니배치</h3>
<p>모든 데이터의 경우에 대하여 손실함수를 구하는데 시간이 많이 걸릴 경우 일부를 추려 ‘근사치’로 이용을 한다고 합니다. 이 때 이용하는 것이 미니 배치 학습이라고 합니다. 이는 통계적으로 모든 세대에 대한 텔레비전 시청률을 구할 때 1,000 가구를 대상으로 측정하는 하여 근사하는 것과 같은 원리입니다. 코드로 표현하면 다음과 같습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">pardir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>

<span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mf">1.</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arrange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">t</span><span class="p">]))</span> <span class="o">/</span> <span class="n">batch_size</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
<span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>

</code></pre></div></div>

<p><br /></p>

<h3 id="손실-함수를-사용하는-이유">손실 함수를 사용하는 이유</h3>
<p>손실함수 사용하는 이유는 신경망 학습에 있어서 <strong>미분</strong>의 역할이 중요합니다. 최적의 매개변수(<em>손실함수 값이 작은 변수</em>)를 찾기 위해서는 매개변수의 변하는 값을 미분하여 미분 값을 기반으로 매개변수를 갱신합니다. 이러한 원리로 매개변수의 손실 함수의 값을 갱신한다고 하면 미분 값이 양수면 매개변수 값을 줄여 손실율을 줄이고 음수이면 매개변수 값을 늘려 손실 함수의 값을 줄일 수 있습니다. 이러한 방법으로 최적의 매개변수를 찾을 수 있습니다. 만약 손실 함수가 아닌 정확도로 찾게 되면 정확도의 경우는 매개변수의 대부분 장소에서 0이 되기 때문입니다.이 경우에는 매개변수를 더이상 갱신할 수 없게 됩니다.</p>
<blockquote>
  <p>시그모이드 함수는 어느 장소라도 0이 되지 않는 성질을 가지고 있는다고 한다.</p>
</blockquote>

<hr />

<h2 id="수치-미분">수치 미분</h2>
<p>경사법에서 기울기 값을 기준으로 나아갈 값을 정합니다. 이를 위해 기울기를 알아야하고, 기울기를 알기 위해 <strong>미분</strong>을 복습하겠습니다.<br />
수치 미분은 어느 한 지점의 수치적인 차분을 계산하여 변화량을 알아내는 것을 의미합니다. 아래 이미지를 참고하시기를 부탁 드립니다.
<br /></p>

<h3 id="미분">미분</h3>
<p align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\bg_black&space;\frac{\mathrm{d}&space;f(x)}{\mathrm{d}&space;x}&space;=&space;\lim_{h-&gt;0}\frac{f(x&plus;h)-f(x))}{h}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\bg_black&space;\frac{\mathrm{d}&space;f(x)}{\mathrm{d}&space;x}&space;=&space;\lim_{h-&gt;0}\frac{f(x&plus;h)-f(x))}{h}" title="\frac{\mathrm{d} f(x)}{\mathrm{d} x} = \lim_{h-&gt;0}\frac{f(x+h)-f(x))}{h}" /></a></p>
<p>미분은 수식에서 보든이 아주 작은 h 변화 동안 함수 f(x)의 변화량 입니다. 이를 구현하면 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">10e-50</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">h</span><span class="p">)</span>

</code></pre></div></div>
<p><br /></p>

<p>이 수식의 문제점은 10e-50에 있습니다. 코드를 float32로 나타내면 0.0이 됩니다. h를 무한히 좁히는 것이 불가능해 생기는 한계입니다. 이를 위하여 차분을 이용하여 다음과 같이 나타냅니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># 0.0001
</span>    <span class="k">return</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<p>이 차분은 x를 기점으로 h 전후 차분을 계산한다는 의미에서 <strong>중심 차분</strong> 혹은 <strong>중앙 차분</strong>이라 합니다.<br />
<br /></p>

<p>다음 함수에 대해서 미분을 하여 확인하면 미분의 의미는 해당 <strong>기울기로 지나는 접선임</strong>을 알 수 있습니다.</p>
<p align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\bg_black&space;y&space;=&space;0.01x^2&space;&plus;&space;0.1x" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\bg_black&space;y&space;=&space;0.01x^2&space;&plus;&space;0.1x" title="y = 0.01x^2 + 0.1x" /></a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="n">plt</span>


<span class="k">def</span> <span class="nf">numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># 0.0001
</span>    <span class="k">return</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">function_1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.01</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">x</span> 


<span class="k">def</span> <span class="nf">tangent_line</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">d</span><span class="o">*</span><span class="n">x</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">d</span><span class="o">*</span><span class="n">t</span> <span class="o">+</span> <span class="n">y</span>
     
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">function_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"x"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"f(x)"</span><span class="p">)</span>

<span class="n">tf</span> <span class="o">=</span> <span class="n">tangent_line</span><span class="p">(</span><span class="n">function_1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><br /></p>
<p align="center"><img src="../img/gredient1.PNG" alt="drawing" style="width:400px;" /></p>
<p><br /></p>

<h3 id="편미분">편미분</h3>
<p align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\bg_black&space;y&space;=&space;x_{0}^2&space;&plus;&space;x_{1}^2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\bg_black&space;y&space;=&space;x_{0}^2&space;&plus;&space;x_{1}^2" title="y = x_{0}^2 + x_{1}^2" /></a></p>

<p>변수 두개가 있을 경우 한쪽에 대하여 미분을 하는 것을 편미분 이라고 합니다.
예를 들어 다음과 같은 함수가 있을 경우 x1에 대하여 미분을 d/dx1, x0이 대하여 미분을 d/x0라고 표현합니다.
이를 구현하면 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_numerical_gradient_no_batch</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># 0.0001
</span>    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># x와 형상이 같은 배열을 생성
</span>    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">tmp_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        
        <span class="c1"># f(x+h) 계산
</span>        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">tmp_val</span><span class="p">)</span> <span class="o">+</span> <span class="n">h</span>
        <span class="n">fxh1</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># f(x-h) 계산
</span>        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span> <span class="o">-</span> <span class="n">h</span> 
        <span class="n">fxh2</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
        
        <span class="n">grad</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fxh1</span> <span class="o">-</span> <span class="n">fxh2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span> <span class="c1"># 값 복원
</span>        
    <span class="k">return</span> <span class="n">grad</span>


<span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_numerical_gradient_no_batch</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">grad</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">_numerical_gradient_no_batch</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">grad</span>


<span class="k">def</span> <span class="nf">function_2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">tangent_line</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">d</span><span class="o">*</span><span class="n">x</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">d</span><span class="o">*</span><span class="n">t</span> <span class="o">+</span> <span class="n">y</span>
     
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">grad</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">])</span> <span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="o">-</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>  <span class="n">angles</span><span class="o">=</span><span class="s">"xy"</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"#666666"</span><span class="p">)</span><span class="c1">#,headwidth=10,scale=40,color="#444444")
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'x0'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'x1'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p align="center"><img src="../img/gredient2.JPG" style="width:400px;" /></p>
<p><br /></p>

<hr />

<h2 id="기울기">기울기</h2>
<p>기울기란 무엇일까요? 책에서는 위의 그래프처럼 기울기가 가리키는 곳은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향으로 설명하고 있습니다. 우리가 필요한 것은 손실률을 줄이는 방법으로 최적의 매개변수를 찾는 것이고, 화살표 방향으로 매개변수를 최적화해 나가는 작업을 말합니다.<br />
<br /></p>

<h3 id="경사법">경사법</h3>
<p>경사법은 지금까지 배운 미분을 이용합니다. 현 위치에서 기울어진 방향으로 일정 거리만큼 이동합니다. 그런 다음 이동한 곳에서도 마찬가지로 기울기를 구하고, 또 그 기울어진 방향으로 나아가기를 반복합니다. 이렇게 해서 함수의 값을 점차 줄이는 것이 <strong>경사법</strong>입니다.<br />
경사법을 수식으로 나타내면 다음과 같습니다.</p>
<p align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\bg_black&space;\binom{x_{0}&space;=&space;x_{0}&space;-&space;\eta&space;\frac{\partial&space;f}{\partial&space;x_{0}}}&space;{x_{1}&space;=&space;x_{1}&space;-&space;\eta&space;\frac{\partial&space;f}{\partial&space;x_{1}}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\bg_black&space;\binom{x_{0}&space;=&space;x_{0}&space;-&space;\eta&space;\frac{\partial&space;f}{\partial&space;x_{0}}}&space;{x_{1}&space;=&space;x_{1}&space;-&space;\eta&space;\frac{\partial&space;f}{\partial&space;x_{1}}}" title="\binom{x_{0} = x_{0} - \eta \frac{\partial f}{\partial x_{0}}} {x_{1} = x_{1} - \eta \frac{\partial f}{\partial x_{1}}}" /></a></p>
<p><br /></p>

<p>n기호는 에타이며 갱신하는 양을 나타냅니다. 이를 신경망에서 <strong>학습률</strong>이라고 표현합니다. 이 값이 너무 크거나 작으면 좋은 장소를 찾아갈 수 없습니다. 보통 이 값을 변경하면서 올바르게 학습하고 있는지를 확인하면서 진행합니다.<br />
이를 구현하면 다음과 같습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">init_x</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">step_num</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">init_x</span>
    <span class="n">x_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_num</span><span class="p">):</span>
        <span class="n">x_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="p">)</span>

        <span class="n">grad</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_history</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<p>여기서 step_num 은 반복 횟수를 의미합니다. lr 에타 * 기울기 만큼 x를 변화하면서 반복해서 미분을 하는 것을 확인할 수 있습니다.<br />
<br /></p>

<h3 id="신경망에서의-기울기">신경망에서의 기울기</h3>
<p>신경망에서 기울기를 다음 예제를 통해 학습합니다. 다음 예제는 softmax 함수를 사용하며, 손실율은 엔트로피로 구합니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">common.functions</span> <span class="kn">import</span> <span class="n">softmax</span><span class="p">,</span> <span class="n">cross_entropy_error</span>
<span class="kn">from</span> <span class="nn">common.gradient</span> <span class="kn">import</span> <span class="n">numerical_gradient</span>


<span class="k">class</span> <span class="nc">simpleNet</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># 정규분포로 초기화
</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">simpleNet</span><span class="p">()</span>

<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">dW</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">dW</span><span class="p">)</span>
</code></pre></div></div>
<p><br /></p>

<blockquote>
  <p>[[ 0.16895522  0.39775333 -0.56670855]<br />
[ 0.25343283  0.59662999 -0.85006282]]</p>
</blockquote>

<p><br /></p>

<p>위 예제를 통해 나온 기울기 결과를 보면 w11을 h만큼 증가시키면 손실함수 값은 0.16h만큼 변화합니다.<br />
w13을 h만큼 증가시키면 손실함수 값은 -0.56h만큼 변화합니다.<br />
이를통해 기울기를 확인하면 손실함수를 얼마나 어느 방향으로 영향을 줄 수 있는지 알 수 있습니다.<br />
<br /></p>

<hr />

<h2 id="학습-알고리즘-구현하기">학습 알고리즘 구현하기</h2>
<p>그동안 기초(‘손실 함수’, ‘미니 배치’, ‘기울기’, ‘경사 하강법’)에 대하여 학습하였습니다. 실제 신경망 학습은 다음 이미지 단계로 진행 됩니다.</p>
<p align="center"><img src="../img/gredient3.png" /></p>

<p>처음에는 시작으로 2층 신경망 클래스 구현으로 시작합니다. 예제를 통해 알아보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">from</span> <span class="nn">common.functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">common.gradient</span> <span class="kn">import</span> <span class="n">numerical_gradient</span>


<span class="k">class</span> <span class="nc">TwoLayerNet</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">weight_init_std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="c1"># 가중치 초기화
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span>
        <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span>
    
        <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
        <span class="n">z1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">y</span>
        
    <span class="c1"># x : 입력 데이터, t : 정답 레이블
</span>    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">accuracy</span>
        
    <span class="c1"># x : 입력 데이터, t : 정답 레이블
</span>    <span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">loss_W</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">grads</span>
        
    <span class="c1"># def gradient(self, x, t):
</span>    <span class="c1">#     W1, W2 = self.params['W1'], self.params['W2']
</span>    <span class="c1">#     b1, b2 = self.params['b1'], self.params['b2']
</span>    <span class="c1">#     grads = {}
</span>        
    <span class="c1">#     batch_num = x.shape[0]
</span>        
    <span class="c1">#     # forward
</span>    <span class="c1">#     a1 = np.dot(x, W1) + b1
</span>    <span class="c1">#     z1 = sigmoid(a1)
</span>    <span class="c1">#     a2 = np.dot(z1, W2) + b2
</span>    <span class="c1">#     y = softmax(a2)
</span>        
    <span class="c1">#     # backward
</span>    <span class="c1">#     dy = (y - t) / batch_num
</span>    <span class="c1">#     grads['W2'] = np.dot(z1.T, dy)
</span>    <span class="c1">#     grads['b2'] = np.sum(dy, axis=0)
</span>        
    <span class="c1">#     da1 = np.dot(dy, W2.T)
</span>    <span class="c1">#     dz1 = sigmoid_grad(a1) * da1
</span>    <span class="c1">#     grads['W1'] = np.dot(x.T, dz1)
</span>    <span class="c1">#     grads['b1'] = np.sum(dz1, axis=0)
</span>
    <span class="c1">#     return grads
</span></code></pre></div></div>
<p><br /></p>

<p>예제를 확인하였을 때, init을 통해 우선 클래스를 초기화(가중치 매개변수, 입력층 갯수, 히든층 갯수, 출력층 갯수) 합니다. 
predict 메소드를 통해 값을 추정하며, accuracy, loss 메소드를 통해 학습 결과를 지표로 나타냅니다. 그리고 numerical_gradient를 통해 기울기를 계산할 수 있습니다. 참고로 주석처리 된 gradient는 다음 장에서 소개한다고 합니다. 이는 오차역전파법을 사용하여 기울기를 효율적이고 빠르게 계산한다고 합니다.</p>

<p>이제 신경망 클래스가 구현되었으니, mnist 예제에 대하여 미니배치를 통해 학습하고 평가하는 과정을 진행하겠습니다. 여기서 <strong>에폭</strong>이라는 용어가 나오는데, 이 에폭은 학습에서 훈련 데이터를 모두 소진했을 때의 횟수에 해당합니다. 미니배치로 100회를 정하였을 경우 100이 1에폭에 해당하게 됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">two_layer_net</span> <span class="kn">import</span> <span class="n">TwoLayerNet</span>

<span class="c1"># 데이터 읽기
</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">TwoLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># 하이퍼파라미터
</span><span class="n">iters_num</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># 반복 횟수를 적절히 설정한다.
</span><span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>   <span class="c1"># 미니배치 크기
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 1에폭당 반복 수
</span><span class="n">iter_per_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters_num</span><span class="p">):</span>
    <span class="c1"># 미니배치 획득
</span>    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="c1"># 기울기 계산
</span>    <span class="c1">#grad = network.numerical_gradient(x_batch, t_batch)
</span>    <span class="n">grad</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    
    <span class="c1"># 매개변수 갱신
</span>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s">'W1'</span><span class="p">,</span> <span class="s">'b1'</span><span class="p">,</span> <span class="s">'W2'</span><span class="p">,</span> <span class="s">'b2'</span><span class="p">):</span>
        <span class="n">network</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    
    <span class="c1"># 학습 경과 기록
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    <span class="n">train_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="c1"># 1에폭당 정확도 계산
</span>    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">iter_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
        <span class="n">train_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
        <span class="n">test_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"train acc, test acc | "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span> <span class="o">+</span> <span class="s">", "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>

<span class="c1"># 그래프 그리기
</span><span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'train'</span><span class="p">:</span> <span class="s">'o'</span><span class="p">,</span> <span class="s">'test'</span><span class="p">:</span> <span class="s">'s'</span><span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_acc_list</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train acc'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test acc'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<blockquote>
  <p>Converting train-images-idx3-ubyte.gz to NumPy Array …<br />
Done<br />
Converting train-labels-idx1-ubyte.gz to NumPy Array …<br />
Done<br />
Converting t10k-images-idx3-ubyte.gz to NumPy Array …<br />
Done<br />
Converting t10k-labels-idx1-ubyte.gz to NumPy Array …<br />
Done<br />
Creating pickle file …<br />
Done! 
train acc, test acc | 0.10441666666666667, 0.1028<br />
train acc, test acc | 0.7746166666666666, 0.7824<br />
train acc, test acc | 0.88065, 0.8863<br />
train acc, test acc | 0.8992333333333333, 0.9016<br />
train acc, test acc | 0.9083166666666667, 0.9111<br />
train acc, test acc | 0.9142166666666667, 0.9175<br />
train acc, test acc | 0.9198666666666667, 0.9215<br />
train acc, test acc | 0.9239833333333334, 0.9242<br />
train acc, test acc | 0.9280166666666667, 0.9281<br />
train acc, test acc | 0.9312833333333334, 0.9311<br />
train acc, test acc | 0.9341333333333334, 0.9338<br />
train acc, test acc | 0.9373, 0.935<br />
train acc, test acc | 0.9392833333333334, 0.9378<br />
train acc, test acc | 0.9414, 0.9391<br />
train acc, test acc | 0.9428166666666666, 0.9403<br />
train acc, test acc | 0.9450333333333333, 0.9429<br />
train acc, test acc | 0.9471666666666667, 0.9449</p>
</blockquote>

<p align="center"><img src="../img/gredient3.JPG" style="width:400px;" /></p>
<p><br /></p>

<p>미니배치를 100회로 지정하고 반복 횟수를 10000회로 설정합니다. 그래프를 확인하면 훈련데이터와 출력데이터 모두 정확도가 차이나지 않습니다.
이는 오버피팅이 일어나지 않았음을 의미합니다. 또한 학습을 반복할 수록 정확도가 올라가는 것을 확인할 수 있습니다.</p>

<hr />

<h2 id="마치며">마치며</h2>
<p>읽어주셔서 감사합니다. “밑바닥부터 시작하는 딥러닝”을 읽으면서 작성하였기 때문에, 부족한 내용이 많습니다. 자세한 내용은 해당 책을 참고하시기를 부탁 드립니다.</p>


					<div class="post-share">
						<ul class="share-list list-reset">
							<li class="share-item">
								<a class="share-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://192.168.219.102:4000/deeplearning-basic/"
								onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
								title="Share on Facebook" rel="nofollow">
									<i class="ion ion-logo-facebook"></i>
								</a>
							</li>
					
							<li class="share-item">
								<a class="share-twitter" href="https://twitter.com/intent/tweet?text=%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5&url=http://192.168.219.102:4000/deeplearning-basic/"
								onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
								title="Share on Twitter" rel="nofollow">
									<i class="ion ion-logo-twitter"></i>
								</a>
							</li>
					
							<li class="share-item">
								<a class="share-linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=http://192.168.219.102:4000/deeplearning-basic/&title=%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5&summary=&source=Mike%20Chu's%20Story%20%7C%20Thank%20you%20for%20visiting."
								onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
								title="Share on LinkedIn" rel="nofollow">
									<i class="ion ion-logo-linkedin"></i>
								</a>
							</li>
					
							<li class="share-item">
								<a class="share-pinterest" href="http://pinterest.com/pin/create/button/?url=http://192.168.219.102:4000/deeplearning-basic/&amp;media=http://192.168.219.102:4000/img/01.jpg&amp;description=%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5"
								onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
								title="Share on Pinterest" rel="nofollow">
									<i class="ion ion-logo-pinterest"></i>
								</a>
							</li>
						</ul>
					</div>
				</div>

				<div class="post-navigation">
					
					<a href="/colliection-2-Kotlin/" class="prev">
						<div class="post-nav-arrow"><i class="ion ion-ios-arrow-round-back"></i> Previous Article</div>
						<h2 class="post-nav-title">코틀린(Kotlin) 컬렉션(Set, Map)-13-</h2>
					</a>
					 
					<a href="/GAN/" class="next">
						<div class="post-nav-arrow">Next Article <i class="ion ion-ios-arrow-round-forward"></i></div>
						<h2 class="post-nav-title">GAN(Generative Adversarial Network)</h2>
					</a>
					
				</div>

			</div>
			
				<div class="comments">
  <div id="disqus_thread" class="article-comments"></div>
  <script>
    (function () {
      var d = document, s = d.createElement('script');
      s.src = '//Mike.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
</div> <!-- /.comments -->
			
	</article> <!-- /.post -->

	<div class="col col-12 col-t-4">
		<aside class="sidebar">
  
  
  <div class="widget widget-recent">
    <h3 class="widget-title">Recent Posts</h3>
    
    <div class="recent-posts">
      
      <div class="recent-header">
        <a class="recent-image" href="/Autoencoder/" style="background-image: url(/img/../img/autoencoder_1.JPG)"></a>
      </div>
      
      <div class="recent-content">
        <h6 class="recent-title"><a href="/Autoencoder/">Autoencoder</a></h6>
        <div class="recent-date">
          <time datetime="2021-11-11T03:40:02+09:00">November 11, 2021</time>
        </div>
      </div>
    </div>
    
    <div class="recent-posts">
      
      <div class="recent-header">
        <a class="recent-image" href="/GAN/" style="background-image: url(/img/../img/gan1.png)"></a>
      </div>
      
      <div class="recent-content">
        <h6 class="recent-title"><a href="/GAN/">GAN(Generative Adversarial Network)</a></h6>
        <div class="recent-date">
          <time datetime="2021-09-09T06:22:42+09:00">September 9, 2021</time>
        </div>
      </div>
    </div>
    
    <div class="recent-posts">
      
      <div class="recent-header">
        <a class="recent-image" href="/deeplearning-basic/" style="background-image: url(/img/01.jpg)"></a>
      </div>
      
      <div class="recent-content">
        <h6 class="recent-title"><a href="/deeplearning-basic/">신경망 학습</a></h6>
        <div class="recent-date">
          <time datetime="2021-07-20T23:21:42+09:00">July 20, 2021</time>
        </div>
      </div>
    </div>
    
    <div class="recent-posts">
      
      <div class="recent-header">
        <a class="recent-image" href="/colliection-2-Kotlin/" style="background-image: url(/img/Kotlin-logo.png)"></a>
      </div>
      
      <div class="recent-content">
        <h6 class="recent-title"><a href="/colliection-2-Kotlin/">코틀린(Kotlin) 컬렉션(Set, Map)-13-</a></h6>
        <div class="recent-date">
          <time datetime="2020-09-27T18:21:22+09:00">September 27, 2020</time>
        </div>
      </div>
    </div>
    
  </div>
  

  <div class="widget widget-social">
    <h3 class="widget-title">Subscribe & Follow</h3>
    <ul class="social-profiles list-reset">
       

        

      
      <li class="social-profiles-item">
        <a href="https://www.instagram.com/mike7chu" class="social-profiles-link"><i class="ion ion-logo-instagram"></i></a>
      </li>
      

       
      
      <li class="social-profiles-item">
        <a href="https://github.com/mike7chu" class="social-profiles-link"><i class="ion ion-logo-github"></i></a>
      </li>
      
      
      <li class="social-profiles-item">
        <a href="https://www.linkedin.com/in/mike-chu-330496b8/?msgOverlay=true" class="social-profiles-link"><i class="ion ion-logo-linkedin"></i></a>
      </li>
      
    </ul>
  </div>

  <div class="widget widget-newsletter">
    <h3 class="widget-title">Newsletter</h3>
    <div class="newsletter-subtitle">Get Interesting News</div>
    <div class="newsletter-text">Receive the latest news via email.</div>
    <form class="c-newsletter-form validate" action="#" method="POST"
      id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_blank" novalidate>
      <div class="newsletter-group">
        <div class="newsletter-group-top">
          <label class="screen-reader-text" for="mce-EMAIL">Email address</label>
          <i class="email-icon ion ion-ios-mail"></i>
          <input class="newsletter-email required email" id="mce-EMAIL" type="text" name="EMAIL" placeholder="E-mail">
        </div>
        <input class="newsletter-button" id="mc-embedded-subscribe" type="submit" name="subscribe" value="Subscribe">
      </div>
    </form>
  </div>

  

  <div class="widget widget-tags">
    <h3 class="widget-title">Tag Cloud</h3>
     
    <ul class="tag-list list-reset">
    
      
        <li class="tag-item"><a href="/tags#Autoencoder" class="tag">Autoencoder</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#Bonobo+Git" class="tag">Bonobo Git</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#Deep+Learning" class="tag">Deep Learning</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#Docker" class="tag">Docker</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#GAN" class="tag">GAN</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#Git" class="tag">Git</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#Kotlin" class="tag">Kotlin</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#OpenVPN" class="tag">OpenVPN</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#Transmission" class="tag">Transmission</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#githubpage" class="tag">githubpage</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#nas" class="tag">nas</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#omv" class="tag">omv</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#raspberrypi" class="tag">raspberrypi</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#samba" class="tag">samba</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#sublime" class="tag">sublime</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#wsl" class="tag">wsl</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98" class="tag">손실함수</a></li>
      
    
      
        <li class="tag-item"><a href="/tags#%EC%8B%A0%EA%B2%BD%EB%A7%9D" class="tag">신경망</a></li>
      
    
    
    </ul>
  </div>
  
</aside> <!-- /.sidebar -->

	</div>

	</div>
</div>

  <footer class="footer">
  <div class="container">
    <div class="row">
      <div class="col col-12">
        <div class="footer-top">
          <h2 class="logo-title">
            <a href="/" class="logo-text">Mike Chu</a>
          </h2>
          <div class="top"><i class="ion ion-ios-arrow-up"></i></div>
        </div>
        <div class="footer-bottom">
          <div class="copyright">
            <p>&copy; 2023 Crafted & Designed by <a href="https://github.com/artemsheludko">Artem Sheludko</a></p>
          </div>
          <div class="footer-social">
            <ul class="list-reset">
               

               

              
              <li><a href="https://www.instagram.com/mike7chu">Instagram</a></li>
              

               

              
              <li><a href="https://github.com/mike7chu">Github</a></li>
              

              
              <li><a href="https://www.linkedin.com/in/mike-chu-330496b8/?msgOverlay=true">LinkedIn</a></li>
              
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</footer> <!-- /.footer -->

  <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/simple-jekyll-search.min.js"></script>
<script>
  SimpleJekyllSearch({
  searchInput: document.getElementById("js-search-input"),
  resultsContainer: document.getElementById("js-results-container"),
  json: "/search.json",
  searchResultTemplate:
    '<li class="search-item"><a class="search-link" href="{url}">{title}</a></li>',
  noResultsText: '<li class="search-no-item">No results found</li>'
  });
</script>
<script src="/js/instafeed.min.js"></script>
<script src="/js/jquery.waitforimages.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
<script src="/js/common.js"></script>


</body>

</html>
